{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.a Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor())\n",
    "\n",
    "testing_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor())\n",
    "\n",
    "training_data.data.shape, testing_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.b DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "training_dataloader = DataLoader(training_data, 64, shuffle=True)\n",
    "testing_dataloader = DataLoader(testing_data, 64, shuffle=False)\n",
    "\n",
    "X, y = next(iter(training_dataloader))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# play with conv layer\n",
    "from torch import nn\n",
    "\n",
    "# build a conv layer with basic parameter\n",
    "# n input channel, n output feature, ks:kenel size, act:activate\n",
    "def conv(ni, nf, ks=3, stride=1, act=True):\n",
    "    layers = [nn.Conv2d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2)]\n",
    "    layers.append(nn.BatchNorm2d(nf))\n",
    "    if act: layers.append(nn.ReLU())\n",
    "    res = nn.Sequential(*layers)\n",
    "    return res\n",
    "\n",
    "def block(ni, nf): return conv(ni, nf)\n",
    "\n",
    "# get model from block\n",
    "def get_model():\n",
    "    return nn.Sequential(\n",
    "            block(1,16),   #14x14\n",
    "            block(16,32),  #7x7\n",
    "            block(32, 64), #4x4\n",
    "            block(64, 128),#2x2\n",
    "            block(128,256),#1x1\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 10))\n",
    "\n",
    "model = get_model()\n",
    "print(X.shape, model(X).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "loss = loss_fn(y_hat, y)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Optimizer SGD\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Combine things together:\n",
    "# train model\n",
    "def train(model, dataloader, optimizer, epochs=2):\n",
    "    size = len(dataloader.dataset)\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            y_hat = model(X)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "\n",
    "            # backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if batch % 300 == 0:\n",
    "                loss, current = loss.item(), batch * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "# optimizer = SGD(model.parameters(), lr=3e-3)\n",
    "# train(model, training_dataloader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testing_dataloader):\n",
    "    size = len(testing_dataloader.dataset)\n",
    "    total = 0\n",
    "    for X, y in testing_dataloader:\n",
    "        y_hat = model(X)\n",
    "        total += sum(y_hat.argmax(1) == y).item()\n",
    "    print(f'Accuracy: {total/size:>2f}')\n",
    "    \n",
    "# test(model, testing_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base-line models:\n",
    "# model = get_model()\n",
    "# optimizer = SGD(model.parameters(), lr=3e-3)\n",
    "# train(model, training_dataloader, optimizer, 10)\n",
    "# test(model, testing_dataloader)\n",
    "# 0.887400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def noop(x):\n",
    "    return x\n",
    "\n",
    "# ResnetBlock\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=2):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "                        conv(ni, nf),\n",
    "                        conv(nf, nf, stride=stride, act=False))\n",
    "        self.pool = noop if stride == 1 else nn.AvgPool2d(stride, ceil_mode=True)\n",
    "        self.idconv = noop if ni == nf else conv(ni, nf, ks=1, act=False)\n",
    "    def forward(self, x):\n",
    "        return nn.ReLU()(self.convs(x) + self.idconv(self.pool(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet block\n",
    "def block(ni, nf): return ResnetBlock(ni, nf)\n",
    "model = get_model()\n",
    "optimizer = SGD(model.parameters(), lr=3e-3)\n",
    "# train(model, training_dataloader, optimizer, 10)\n",
    "# test(model, testing_dataloader)\n",
    "# 0.893100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.428055  [    0/60000]\n",
      "loss: 0.500507  [19200/60000]\n",
      "loss: 0.313588  [38400/60000]\n",
      "loss: 0.367805  [57600/60000]\n",
      "loss: 0.399477  [    0/60000]\n",
      "loss: 0.234004  [19200/60000]\n",
      "loss: 0.232941  [38400/60000]\n",
      "loss: 0.393569  [57600/60000]\n",
      "loss: 0.208819  [    0/60000]\n",
      "loss: 0.369349  [19200/60000]\n",
      "loss: 0.428407  [38400/60000]\n",
      "loss: 0.279916  [57600/60000]\n",
      "loss: 0.207196  [    0/60000]\n",
      "loss: 0.175709  [19200/60000]\n",
      "loss: 0.234070  [38400/60000]\n",
      "loss: 0.387717  [57600/60000]\n",
      "loss: 0.272289  [    0/60000]\n",
      "loss: 0.176166  [19200/60000]\n",
      "loss: 0.205463  [38400/60000]\n",
      "loss: 0.204345  [57600/60000]\n",
      "loss: 0.265925  [    0/60000]\n",
      "loss: 0.273075  [19200/60000]\n",
      "loss: 0.263643  [38400/60000]\n",
      "loss: 0.161081  [57600/60000]\n",
      "loss: 0.082600  [    0/60000]\n",
      "loss: 0.183584  [19200/60000]\n",
      "loss: 0.092436  [38400/60000]\n",
      "loss: 0.250213  [57600/60000]\n",
      "loss: 0.079052  [    0/60000]\n",
      "loss: 0.176493  [19200/60000]\n",
      "loss: 0.146372  [38400/60000]\n",
      "loss: 0.146396  [57600/60000]\n",
      "loss: 0.051742  [    0/60000]\n",
      "loss: 0.130683  [19200/60000]\n",
      "loss: 0.209712  [38400/60000]\n",
      "loss: 0.117252  [57600/60000]\n",
      "loss: 0.114045  [    0/60000]\n",
      "loss: 0.095931  [19200/60000]\n",
      "loss: 0.029574  [38400/60000]\n",
      "loss: 0.079300  [57600/60000]\n",
      "Accuracy: 0.890700\n"
     ]
    }
   ],
   "source": [
    "# stack block\n",
    "def block(ni, nf): return nn.Sequential(ResnetBlock(ni, nf), ResnetBlock(nf, nf, stride=1))\n",
    "model = get_model()\n",
    "optimizer = SGD(model.parameters(), lr=3e-3)\n",
    "train(model, training_dataloader, optimizer, 10)\n",
    "test(model, testing_dataloader)\n",
    "# 0.893100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
